{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPS数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPS数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dire = 'data_new_pro.csv'\n",
    "\n",
    "data_location = pd.read_csv(path_dire)\n",
    "\n",
    "data_location.head(1)\n",
    "\n",
    "# # 统计每一个id的个数：\n",
    "# id_count = {}\n",
    "# col = data_location.ID.unique()\n",
    "# for i in col:\n",
    "#     d1 = data_location[data_location.ID == i]\n",
    "#     id_count[i] = len(d1)\n",
    "    \n",
    "# count = list(id_count.values())\n",
    "# id_count = pd.DataFrame(count, index=col)\n",
    "# id_count.to_csv('id_count.csv')\n",
    "\n",
    "id_count = pd.read_csv('id_count.csv',index_col='Unnamed: 0')\n",
    "id_count.head()\n",
    "\n",
    "id_max = np.argmax(id_count['0'])  # 最大的id的个数\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "# 图名，图例，轴标签，轴边界，轴刻度，轴刻度标签等\n",
    "\n",
    "df = pd.DataFrame(np.random.rand(10,2),columns=['A','B'])\n",
    "fig = df.plot(figsize=(12, 6))\n",
    "# figsize：创建图表窗口，设置窗口大小\n",
    "# 创建图表对象，并赋值与fig\n",
    "\n",
    "plt.title('Interesting Graph - Check it out')  # 图名\n",
    "plt.xlabel('Plot Number')  # x轴标签\n",
    "plt.ylabel('Important var') # y轴标签\n",
    "\n",
    "plt.legend(loc = 'upper right')  \n",
    "# 显示图例，loc表示位置\n",
    "# 'best'         : 0, (only implemented for axes legends)(自适应方式)\n",
    "# 'upper right'  : 1,\n",
    "# 'upper left'   : 2,\n",
    "# 'lower left'   : 3,\n",
    "# 'lower right'  : 4,\n",
    "# 'right'        : 5,\n",
    "# 'center left'  : 6,\n",
    "# 'center right' : 7,\n",
    "# 'lower center' : 8,\n",
    "# 'upper center' : 9,\n",
    "# 'center'       : 10,\n",
    "\n",
    "plt.xlim([0,12])  # x轴边界\n",
    "plt.ylim([0,1.5])  # y轴边界\n",
    "plt.xticks(range(10))  # 设置x刻度\n",
    "plt.yticks([0,0.2,0.4,0.6,0.8,1.0,1.2])  # 设置y刻度\n",
    "fig.set_xticklabels(\"%.1f\" %i for i in range(10))  # x轴刻度标签 保留小数点后一位小数\n",
    "fig.set_yticklabels(\"%.2f\" %i for i in [0,0.2,0.4,0.6,0.8,1.0,1.2])  # y轴刻度标签 #保留小数点后2位小数\n",
    " # 范围只限定图表的长度，刻度则是决定显示的标尺 → 这里x轴范围是0-12，但刻度只是0-9，刻度标签使得其显示1位小数 # 轴标签则是显示刻度的标签 print(fig,type(fig)) # 查看表格本身的显示方式，以及类别\n",
    "\n",
    "\n",
    " \"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "# 对于 id的个数画图，查看一下，id的数量分布\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "#新加入的代码如下：\n",
    "plt.xlabel(\"id号\") #x轴说明\n",
    "plt.ylabel(\"id的计数\") #y轴说明\n",
    "plt.title(\"车辆的id的计数\") #此图像的标题\n",
    "\n",
    "plt.scatter(range(len(id_count)), id_count)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "# 由数据的分布可知，大部分车辆的GPS记录数据在10000个以下\n",
    "\n",
    "len(id_count[id_count['0'] > 10000])\n",
    "\n",
    "# 大于10000 的数据记录只有230个\n",
    "\n",
    "\n",
    "\n",
    "len(id_count[id_count['0'] < 20])\n",
    "\n",
    "# 数据点小于20个的车辆记录有1/3\n",
    "\n",
    "\n",
    "len(id_count[id_count['0'] < 100])  # 数据点小于100个的车辆记录有10354\n",
    "\n",
    "\n",
    "\n",
    "len(id_count[id_count['0'] < 10])   # 数据点小于10个的车辆记录有3555\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "\n",
    "# 车辆的GPS数据的记录的点很少的话没法进行轨迹的挖掘以及，返程的判定\n",
    "# 查看 个数小于10的id\n",
    "id_count[id_count['0'] < 10]\n",
    "\n",
    "\n",
    "# 查看id=113765的车辆\n",
    "data_location[data_location.ID==113765]\n",
    "\n",
    "# 由此可以看出车辆id为113785的车的数据记录很小，则出现的地点的个数很小，且基本\n",
    "\n",
    "\n",
    "# 去出6月30日的id = 37532 数据\n",
    "\n",
    "data_37532_6_30 = data_37532[np.array([data_37532.time.iloc[i].date() for i in range(35555)]) == datetime.date(2018, 6, 30)]\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "# 对于 id的个数画图，查看一下，id的数量分布\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "#新加入的代码如下：\n",
    "# plt.xlabel(\"\") #x轴说明\n",
    "# plt.ylabel(\"id的计数\") #y轴说明\n",
    "plt.title(\"车辆的经纬度\") #此图像的标题\n",
    "plt.scatter(data_37532_6_30['gpsX'], data_37532_6_30['gpsY'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "dis_37532_6_30 = []\n",
    "speed_ave_37532_6_30 = []\n",
    "data_37532_6_30.time = pd.to_datetime(data_37532_6_30.time)\n",
    "for i, j in zip(data_37532_6_30.index[::-1][:-1], data_37532_6_30.index[::-1][1:]):\n",
    "    dis = round(geodesic(data_37532_6_30.loc[i][['gpsY','gpsX']],data_37532_6_30.loc[j][['gpsY','gpsX']]).m)\n",
    "    tim = (data_37532_6_30.loc[j]['time']-data_37532_6_30.loc[i]['time']).total_seconds()\n",
    "    if tim==0:\n",
    "        v  = 0\n",
    "    else:\n",
    "        v = round(dis/tim, 2)\n",
    "    dis_37532_6_30.append(dis)\n",
    "    speed_ave_37532_6_30.append(v)\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "# 取出一个速度异常的值，看一下是哪一天\n",
    "# 9837642\n",
    "\n",
    "data_37532.loc[9837642]\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "# 去出6月30日的id = 37532 数据\n",
    "data_37532_1_03 = data_37532[np.array([data_37532.time.iloc[i].date() for i in range(35555)]) == datetime.date(2018, 1, 3)]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "# 对于 id的个数画图，查看一下，id的数量分布\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "#新加入的代码如下：\n",
    "# plt.xlabel(\"\") #x轴说明\n",
    "# plt.ylabel(\"id的计数\") #y轴说明\n",
    "plt.title(\"车辆的经纬度\") #此图像的标题\n",
    "plt.scatter(data_37532_1_03['gpsX'], data_37532_1_03['gpsY'])\n",
    "plt.show()\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "dis_37532_1_03 = []\n",
    "speed_ave_37532_1_03 = []\n",
    "data_37532_1_03.time = pd.to_datetime(data_37532_1_03.time)\n",
    "for i, j in zip(data_37532_1_03.index[::-1][:-1], data_37532_1_03.index[::-1][1:]):\n",
    "    dis = round(geodesic(data_37532_1_03.loc[i][['gpsY','gpsX']],data_37532_1_03.loc[j][['gpsY','gpsX']]).m)\n",
    "    tim = (data_37532_1_03.loc[j]['time']-data_37532_1_03.loc[i]['time']).total_seconds()\n",
    "    if tim==0:\n",
    "        v  = 0\n",
    "    else:\n",
    "        v = round(dis/tim, 2)\n",
    "    dis_37532_1_03.append(dis)\n",
    "    speed_ave_37532_1_03.append(v)\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "d_final = speed_ave_37532_1_03[-1]\n",
    "speed_ave_37532_1_03.append(-1)\n",
    "speed_ave_37532_1_03 = pd.DataFrame(speed_ave_37532_1_03, index=data_37532_1_03.index)\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "np.where(speed_ave_37532_1_03[0] > 33.33)[0]\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "v_large_33_33 = list(np.where(speed_ave_37532_1_03[0] > 33.33)[0])\n",
    "df_lar_33 = data_37532_1_03.iloc[v_large_33_33]\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "# 对于 id的个数画图，查看一下，id的数量分布\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "#新加入的代码如下：\n",
    "# plt.xlabel(\"\") #x轴说明\n",
    "# plt.ylabel(\"id的计数\") #y轴说明\n",
    "plt.title(\"车辆的经纬度\") #此图像的标题\n",
    "plt.scatter(data_37532_1_03['gpsX'], data_37532_1_03['gpsY'])\n",
    "# plt.scatter(df_lar_33['gpsX'], df_lar_33['gpsY'], marker='*', color = 'red')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "# 速度的计算不对，修正：\n",
    "\n",
    "def trace_car_speed(trace_car):\n",
    "    \"\"\"\n",
    "    :param trace_car:由take_traceofcar 返回的单个车辆轨迹数据\n",
    "    :return: 车辆每个轨迹点的速度数据\n",
    "    \"\"\"\n",
    "    # 计算每个点的速度\n",
    "    velocity_temp = np.zeros(len(trace_car))\n",
    "    # 记录从d12,d23,d(n-1,n)的距离\n",
    "    dis_temp = np.array([geodesic(trace_car.iloc[i][['gpsY', 'gpsX']], trace_car.iloc[i + 1][['gpsY', 'gpsX']]).m \\\n",
    "                         for i in range(len(trace_car) - 1)])\n",
    "    # 记录从t12,t23,t(n-1,n)的时间\n",
    "    time_temp = np.array([(trace_car.iloc[i+1]['time'] - trace_car.iloc[i]['time']).total_seconds() \\\n",
    "                          for i in range(len(trace_car) - 1)])\n",
    "\n",
    "    for i in range(len(trace_car) - 1):\n",
    "        if i == 0:\n",
    "            velocity_temp[0] = dis_temp[0] / time_temp[0]\n",
    "        elif i == len(trace_car) - 1:\n",
    "            velocity_temp[len(trace_car) - 1] = dis_temp[len(trace_car) - 2] / time_temp[len(trace_car) - 2]\n",
    "        else:\n",
    "            velocity_temp[i] = (dis_temp[i - 1] + dis_temp[i]) / (time_temp[i - 1] + time_temp[i])\n",
    "\n",
    "    return velocity_temp\n",
    "\n",
    "trace_car_speed(data_37532_1_03[::-1])\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "v = trace_car_speed(data_37532_1_03[::-1])\n",
    "v[v>33.33]\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "v_ = pd.DataFrame(v, index = data_37532_1_03[::-1].index)\n",
    "v_[v_[0] > 33.33]\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "nd_del = v_[v_[0] > 33.33].index\n",
    "data_37532_1_03_del_33 = data_37532_1_03.drop(ind_del)\n",
    "data_37532_1_03_del_33\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "data_37532_1_03_del = data_37532_1_03.loc[v_[v_[0] > 33.33].index]\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "# 对于 id的个数画图，查看一下，id的数量分布\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "#新加入的代码如下：\n",
    "# plt.xlabel(\"\") #x轴说明\n",
    "# plt.ylabel(\"id的计数\") #y轴说明\n",
    "plt.title(\"车辆的经纬度\") #此图像的标题\n",
    "plt.scatter(data_37532_1_03_del_33['gpsX'], data_37532_1_03_del_33['gpsY'])\n",
    "plt.scatter(data_37532_1_03_del['gpsX'], data_37532_1_03_del['gpsY'], marker='*', color = 'red')\n",
    "plt.show()\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "v_del = trace_car_speed(data_37532_1_03_del_33[::-1])\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "# 重新计算速度\n",
    "v_del = pd.DataFrame(v_del,index = data_37532_1_03_del_33[::-1].index)\n",
    "v_del[v_del[0] > 33.33]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "# 对于 id的个数画图，查看一下，id的数量分布\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "data_37532_1_03_del_second = data_37532_1_03_del_33.loc[v_del[v_del[0] > 33.33].index]\n",
    "#新加入的代码如下：\n",
    "# plt.xlabel(\"\") #x轴说明\n",
    "# plt.ylabel(\"id的计数\") #y轴说明\n",
    "plt.title(\"车辆的经纬度\") #此图像的标题\n",
    "plt.scatter(data_37532_1_03_del_33['gpsX'], data_37532_1_03_del_33['gpsY'], alpha=0.1)\n",
    "plt.scatter(data_37532_1_03_del['gpsX'], data_37532_1_03_del['gpsY'], marker='*', color = 'red')\n",
    "plt.scatter(data_37532_1_03_del_second['gpsX'], data_37532_1_03_del_second['gpsY'], marker='*', color = 'red')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "# 对于 id的个数画图，查看一下，id的数量分布\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "#新加入的代码如下：\n",
    "# plt.xlabel(\"\") #x轴说明\n",
    "# plt.ylabel(\"id的计数\") #y轴说明\n",
    "plt.title(\"车辆的经纬度\") #此图像的标题\n",
    "plt.scatter(data_37532_1_03_del_33_['gpsX'], data_37532_1_03_del_33_['gpsY'], alpha=0.1)\n",
    "plt.scatter(data_37532_1_03_del['gpsX'], data_37532_1_03_del['gpsY'], marker='*', color = 'red')\n",
    "plt.scatter(data_37532_1_03_del_second['gpsX'], data_37532_1_03_del_second['gpsY'], marker='*', color = 'green')\n",
    "plt.show()\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "v_del_ = trace_car_speed(data_37532_1_03_del_33_[::-1])\n",
    "# 重新计算速度\n",
    "v_del_ = pd.DataFrame(v_del_,index = data_37532_1_03_del_33_[::-1].index)\n",
    "v_del_[v_del_[0] > 33.33]\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "# 对于数据的异常值整体的删除 , 但是数据太大，大概六天跑完，放弃了，选择和推挤相关的数据进行数据的处理\n",
    "def data_outlier_del(data):\n",
    "    data.time = pd.to_datetime(data.time)\n",
    "    data = data[::-1]\n",
    "    v = trace_car_speed(data)\n",
    "    while True in list(v>33.33):\n",
    "        v = pd.DataFrame(v, index = data.index)\n",
    "        ind_del = v[v[0]>33.33].index\n",
    "        data = data.drop(ind_del)\n",
    "        v = trace_car_speed(data)\n",
    "    data['speed_ave'] = v\n",
    "    return data\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "# 对于数据少于10个的记录直接删除\n",
    "\n",
    "# 花了两个小时\n",
    "\n",
    "id_count_less_10 = id_count[id_count['0'] < 10].index\n",
    "for i in id_count_less_10:\n",
    "    data_del_ind = data_location[data_location.ID == i].index\n",
    "    data_location = data_location.drop(data_del_ind)\n",
    "\n",
    "\n",
    "data_location.to_csv('data_location_del_less_10.csv')\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "# 计算速度  花费时间久，\n",
    "data = []\n",
    "for i in data_location.ID.unique():\n",
    "    data_id = data_location[data_location.ID == i]\n",
    "    data_id_ =  data_outlier_del(data_id)\n",
    "    data.append(data_id)\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "data.to_csv('finish_processing.csv',index=None)\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "对于每一辆车按速度的划分：\n",
    "\n",
    "# 读取数据\n",
    "\n",
    "def read_cs(path):\n",
    "    data = pd.read_csv(path)\n",
    "    data.time = pd.to_datetime(data.time)\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "day = [data_lo.time.iloc[i].date().strftime('%Y-%m-%d') for i in range(len(data_lo))]  # 把time 转换有y_m_d的字符串类型\n",
    "\n",
    "data_lo['day'] = day  # 把 day 加入到 data_lo数据集\n",
    "\n",
    "data_lo.to_csv('data_location_del_less_10.csv', index=None)  # 保存数据\n",
    "\n",
    "d1 = data_lo.groupby(\"ID\")[\"day\"].value_counts()  # 按ID对数据进行分组，在每个ID中按day统计个数， 知道每个ID下一共有多少天的数据，每天的数据量是多少\n",
    "\n",
    "d1.to_csv('day_counts_point.csv')  # 保存id下每天的记录\n",
    "\n",
    "d1 = pd.read_csv('day_counts_point.csv', index_col=None)  # 读取数据\n",
    "\n",
    "d2 = d1.groupby(\"ID\")[\"count\"].agg(['max','min','mean','count','sum', 'median','std','var'])  # 使用 agg将多个函数功能合并展示\n",
    "\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 车辆基础数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 车辆基础数据的处理：\n",
    "\n",
    "# 数据导入\n",
    "\n",
    "path = '/Users/snszz/Desktop/python/物流数据/大赛数据/赛题一/车辆基础数据.txt'\n",
    "\n",
    "car_funda = pd.read_table(path, sep=',',header=None, \\\n",
    "                          names=['ID', 'license','car_length','type','max_weight','max_volume'])\n",
    "print(\"原始的基础数据的大小\", car_funda.shape)\n",
    "# 删除任何行为空的为空的数据\n",
    "\n",
    "# https://blog.csdn.net/roger_royer/article/details/81125128\n",
    "\n",
    "car_funda = car_funda.dropna(axis=0,how='any')\n",
    "\n",
    "print(\"删除空缺值后数据的大小\", car_funda.shape)\n",
    "\n",
    "# car_funda.describe()  # 查看整体\n",
    "\n",
    "#删除，车长，最大吨数，最大方数为零的数据\n",
    "\n",
    "car_funda = car_funda[(car_funda.car_length!=0)&\\\n",
    "                      (car_funda.max_weight!=0)&\\\n",
    "                      (car_funda.max_volume!=0)]   # 处理之后还有79747个车辆的id， 因为数据中多数是吨数和方数都为0\n",
    "\n",
    "print(\"删除空缺值，以及车长，最大吨数，最大方数为零之后数据的大小\", car_funda.shape)\n",
    "# 对此只需要处李基础数据对应的GPS数据\n",
    "\"\"\"----------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "# 画散点图查看数据最大方数和最大吨数是否匹配\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "#新加入的代码如下：\n",
    "plt.xlabel(\"max_weight\") #x轴说明\n",
    "plt.ylabel(\"max_volume\") #y轴说明\n",
    "# plt.title(\"车辆的经纬度\") #此图像的标题\n",
    "plt.scatter(car_funda['max_weight'], car_funda['max_volume'], color='red',marker='.')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\"\"\"----------------------------------------------------------------------------------\"\"\"\n",
    "# 排序查看，发现方数吨数不匹配\n",
    "\n",
    "car_funda.sort_values([\"max_volume\"],ascending=False)  # 按max_volume排列数据\n",
    "\n",
    "car_funda.sort_values([\"max_weight\"],ascending=False)  # 按max_volume排列数据\n",
    "\n",
    "car_funda.max_weight.median()  # 查看吨数的中位数： 75.0\n",
    "\n",
    "car_funda.max_volume.median()  # 查看方数的中位数：30.0\n",
    "\n",
    "\"\"\"----------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "\n",
    "# 计算吨数与方数的比例，方数与吨数的比例，取大于1的, max(吨数/方数，方数/吨数)<=200\n",
    "a = car_funda['max_weight']/car_funda['max_volume']\n",
    "\n",
    "c = pd.concat([a,1/a], axis=1)\\\n",
    "\n",
    "car_funda['raito'] = c[[0,1]].max(axis=1)\n",
    "\n",
    "car_funda = car_funda[car_funda.raito <= 200]\n",
    "\n",
    "print(\"删除方数吨数不匹配的数据之后：\", car_funda.shape)\n",
    "\n",
    "car_funda.to_csv('car_funda_processing.csv', index=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 车辆基础数据和GPS数据的合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "data_location = pd.read_csv('data_new_pro.csv')\n",
    "car_funda = pd.read_csv('car_funda_processing.csv')\n",
    "data_location.head(1)\n",
    "\n",
    "data_location1 = data_location[['ID', 'gpsX', 'gpsY', 'time', 'province', 'city', 'strict', 'detail',\n",
    "       'speed']]\n",
    "\n",
    "# 车辆基础数据与GPS数据的合并，两个都有的ID才留下  # how='inner' 更好直接保留两个id都存在的数据\n",
    "\n",
    "data_location2 = data_location1.merge(car_funda,how='right',on='ID')\n",
    "\n",
    "# 删除 任何有空缺值的行\n",
    "\n",
    "data_location3 = data_location2.dropna(axis=0,how='any')  # 还有 9978645个数据\n",
    "\n",
    "# 保存数据\n",
    "# data_location3.to_csv('data_new_pro.csv', index=None)\n",
    "\n",
    "data_location4 = pd.read_csv('data_location_del_less_10.csv')\n",
    "\n",
    "# 预处理后的数据合并\n",
    "\n",
    "data_location5 = data_location4.merge(car_funda,how='inner',on='ID')\n",
    "\n",
    "# data_location3.to_csv('data_location_del_less_10.csv', index=None)  # 9968286 rows × 20 columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 物流数据处理流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "path_dire = 'data_new_pro.csv'\n",
    "\n",
    "data_location2 = pd.read_csv(path_dire)\n",
    "\n",
    "id_count = pd.read_csv('id_count.csv', header=None, names=['ID','count'])\n",
    "\n",
    "car_funda = pd.read_csv('car_funda_processing.csv')\n",
    "\n",
    "id_count  = id_count.drop(0, axis=0)\n",
    "\n",
    "id_del = list(id_count[id_count['count'] < 20].ID)  # 删除个数大于20的GPS数据\n",
    "\n",
    "data_location2 = data_location2[~data_location2['ID'].isin(id_del)]  # df1 = df1[~df1['A'].isin([1])]\n",
    "\n",
    "data_location2.time = pd.to_datetime(data_location2.time)\n",
    "\n",
    "day = [str(data_location2.time.iloc[i].date()) for i in range(len(data_location2))]\n",
    "\n",
    "data_location2['day'] = day\n",
    "\n",
    "data_location2 = data_location2.merge(car_funda,how='inner',on='ID')\n",
    "\n",
    "data_location2.to_csv('GPS_pro.csv', index=None)\n",
    "\n",
    "\n",
    "\"\"\"-------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "\n",
    "path_dire = 'GPS_pro.csv'\n",
    "\n",
    "data_location = pd.read_csv(path_dire)\n",
    "\n",
    "data_location.head(1)\n",
    "\n",
    "len(data_location)  # 查看数据的大小9938122 data.shape, columns, index, describe(), info(),\n",
    "\n",
    "# 一共多少个省\n",
    "\n",
    "print(len(data_location.province.unique()),\n",
    "     len(data_location.city.unique()),\n",
    "     len(data_location.strict.unique()))  # 一共40个省，367个县， 2703个市区\n",
    "\n",
    "# 一共多少个车\n",
    "\n",
    "print(len(data_location.ID.unique()))  # 处理后一共11039\n",
    "\n",
    "\n",
    "# 把time，按天存储， 以便按天统计每一天的数据个数\n",
    "\n",
    "# day = [data_lo.time.iloc[i].date().strftime('%Y-%m-%d') for i in range(len(data_lo))]  # 把time 转换有y_m_d的字符串类型\n",
    "\n",
    "# data_lo['day'] = day  # 把 day 加入到 data_lo数据集\n",
    "\n",
    "# data_lo.to_csv('data_location_del_less_10.csv', index=None)  # 保存数据\n",
    "\n",
    "\n",
    "\n",
    "# 每个车有几天的数据， 每天的数据量是多少，最大，最小，均值， 使用groupby,按ID分组，再按day进行统计\n",
    "\n",
    "# d1 = data_location.groupby(\"ID\")[\"day\"].value_counts()  # 按ID对数据进行分组，在每个ID中按day统计个数， 知道每个ID下一共有多少天的数据，每天的数据量是多少\n",
    "\n",
    "# d1.to_csv('day_counts_point.csv')  # 保存id下每天的记录\n",
    "\n",
    "d1 = pd.read_csv('day_counts_point.csv', index_col=None)  # 读取数据\n",
    "\n",
    "d2 = d1.groupby(\"ID\")[\"day.1\"].agg(['max','min','mean','count','sum'])  # 使用 agg将多个函数功能合并展示, 'sum', 'median','std','var' \n",
    "            # 例如ID=24656, 最多的一天有117个数据， 最少的一天只有1个数据，共6天的数据， 统计了225个数据\n",
    "\n",
    "# 数据最多的数据\n",
    "\n",
    "#  np.argmax(d2['sum'])  # 2212\n",
    "\n",
    "#d2.iloc[2212]  # ID = 94000, 一共39926个数\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"-----------------------------------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "# 1). 对id=94000的数据进行挖掘，其他的车辆的处理与该车辆的处理方式一样，只是数据很大，花费的时间很多，\n",
    "\n",
    "df_94000 = data_location[data_location.ID == 94000]\n",
    "\n",
    "# 2). 对于该数据采取可视化的手段， 差看每天多少个数据\n",
    "\n",
    "day_94000 = d1[d1.ID == 94000]  # 一共181天\n",
    "\n",
    "# 用柱状图查看每天\n",
    "\n",
    "#  无论是条形图还是散点图都可以看出数据的分布比较均匀， 在200-240范围内的\n",
    "\n",
    "# len(ID_94000[ID_94000['day.1'] > 200]) / len(ID_94000)  # 占91.7% 的比例\n",
    "\n",
    "\"\"\"-----------------------------------------------------------------------------------------------------------\"\"\"\n",
    "#  2.1） 条形图\n",
    "\n",
    "# 构建数据\n",
    "ID_94000 = d1[d1.ID == 94000]\n",
    "x = pd.to_datetime(ID_94000.day)\n",
    "y = ID_94000['day.1']\n",
    "fig = plt.figure(figsize=(25,10))\n",
    "# 绘图\n",
    "plt.bar(x=x, height=y, label='数量', color='steelblue', alpha=0.8)\n",
    "# 在柱状图上显示具体数值, ha参数控制水平对齐方式, va控制垂直对齐方式\n",
    "\n",
    "# 设置标题\n",
    "plt.title(\"id=94000的车辆的GPS数据分布(按天统计)\")\n",
    "# 为两条坐标轴设置名称\n",
    "plt.xlabel(\"日期\")\n",
    "plt.ylabel(\"GPS数量\")\n",
    "# 显示图例\n",
    "plt.legend()\n",
    "# plt.savefig(\"a.jpg\")\n",
    "plt.show()\n",
    "\n",
    "\"\"\"-----------------------------------------------------------------------------------------------------------\"\"\"\n",
    "# 2.2） 散点图\n",
    "\n",
    "# 构建数据\n",
    "ID_94000 = d1[d1.ID == 94000]\n",
    "x = pd.to_datetime(ID_94000.day)\n",
    "y = ID_94000['day.1']\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "# 绘图\n",
    "plt.scatter(x, y, label='数量', color='red', alpha=1)\n",
    "# 在柱状图上显示具体数值, ha参数控制水平对齐方式, va控制垂直对齐方式\n",
    "\n",
    "# 设置标题\n",
    "plt.title(\"id=94000的车辆的GPS数据分布(按天统计)\")\n",
    "# 为两条坐标轴设置名称\n",
    "plt.xlabel(\"日期\")\n",
    "plt.ylabel(\"GPS数量\")\n",
    "# 显示图例\n",
    "plt.legend()\n",
    "# plt.savefig(\"a.jpg\")\n",
    "plt.show()\n",
    "\n",
    "\"\"\"-----------------------------------------------------------------------------------------------------------\"\"\"\n",
    "# 画图展示数据的整体分布\n",
    "\n",
    "# 2.2） 三维散点图， 要有时间才能看出规律\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def three_de(data):\n",
    "    plt.rcParams['legend.fontsize'] = 10\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    ax = fig.gca(projection='3d')  # get current axes\n",
    "\n",
    "    # Prepare arrays x, y, z\n",
    "\n",
    "    # x = pd.to_datetime(df_94000['time']).to_list()\n",
    "\n",
    "    x = [i for i in  range(len(data))]\n",
    "\n",
    "    y = data['gpsX'].to_list()\n",
    "\n",
    "    z = data['gpsY'].to_list()\n",
    "\n",
    "    ax.scatter(x, y, z, label='gps点', color='red')\n",
    "    ax.legend()  # legend content dertermined by label above\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "three_de(df_94000)\n",
    "\n",
    "\n",
    "\"\"\"-----------------------------------------------------------------------------------------------------------\"\"\"\n",
    "#  具体谋一天6-30\n",
    "\n",
    "df_94000_6_30 = df_94000[df_94000.day == df_94000.day.iloc[0]]\n",
    "three_de(df_94000_6_30)\n",
    " #比较\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"-----------------------------------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "\n",
    "# 对于day进行查看， 知道具体那些天有数据\n",
    "\n",
    "\n",
    "ID_94000.day = pd.to_datetime(ID_94000.day)\n",
    "ID_94000 = ID_94000.sort_values(by='day',ascending=False, inplace=True)\n",
    "\n",
    "\"\"\"\n",
    "可以发现所给的数据并是连续的的天数，对于这样的数据，可以直接的处理的话，\n",
    "\"\"\"\n",
    "# 原文是瞬时速度不能表示该时间段内的速度，定义速度函数，以平均速度表示该点的速度 vi = (di+d_i+1)/(ti,t_i+1)  v0=v1, vn= v_n-1\n",
    "\n",
    "\n",
    "def trace_car_speed(trace_car):\n",
    "    \"\"\"\n",
    "    :param trace_car:由take_traceofcar 返回的单个车辆轨迹数据\n",
    "    :return: 车辆每个轨迹点的速度数据\n",
    "    \"\"\"\n",
    "    # 计算每个点的速度\n",
    "    velocity_temp = np.zeros(len(trace_car))\n",
    "    # 记录从d12,d23,d(n-1,n)的距离\n",
    "    dis_temp = np.array([geodesic(trace_car.iloc[i][['gpsY', 'gpsX']], trace_car.iloc[i + 1][['gpsY', 'gpsX']]).m \\\n",
    "                         for i in range(len(trace_car) - 1)])\n",
    "    # 记录从t12,t23,t(n-1,n)的时间\n",
    "    time_temp = np.array([(trace_car.iloc[i+1]['time'] - trace_car.iloc[i]['time']).total_seconds() \\\n",
    "                          for i in range(len(trace_car) - 1)])\n",
    "\n",
    "    for i in range(len(trace_car) - 1):\n",
    "        if i == 0:\n",
    "            velocity_temp[0] = dis_temp[0] / time_temp[0]\n",
    "        elif i == len(trace_car) - 1:\n",
    "            velocity_temp[len(trace_car) - 1] = dis_temp[len(trace_car) - 2] / time_temp[len(trace_car) - 2]\n",
    "        else:\n",
    "            velocity_temp[i] = (dis_temp[i - 1] + dis_temp[i]) / (time_temp[i - 1] + time_temp[i])\n",
    "\n",
    "    return velocity_temp\n",
    "\"\"\"-----------------------------------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "df_94000.time = pd.to_datetime(df_94000.time)\n",
    "\n",
    "df_94000 = df_94000[::-1]  # 时间从小到大排列\n",
    "\n",
    "v_94000 = trace_car_speed(df_94000) # 速度计算\n",
    "\n",
    "df_94000['speed_ave'] = v_94000\n",
    "\n",
    "\n",
    "df_94000[df_94000.speed_ave >33.33]  # 查看速度大于33.33m/s的数据\n",
    "\n",
    "\"\"\"-----------------------------------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# 画图查看异常点：\n",
    "\"\"\"------------------------------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "# 对于 id的个数画图，查看一下，id的数量分布\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "df_94000_lar_33 = df_94000[df_94000.speed_ave >33.33]\n",
    "\n",
    "#新加入的代码如下：\n",
    "plt.xlabel(\"经度\") #x轴说明\n",
    "plt.ylabel(\"纬度\") #y轴说明\n",
    "plt.title(\"车辆的经纬度\") #此图像的标题\n",
    "plt.scatter(df_94000['gpsX'], df_94000['gpsY'], alpha=0.1)\n",
    "\n",
    "plt.scatter(df_94000_lar_33['gpsX'], df_94000_lar_33['gpsY'], marker='*', color = 'red')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 整体看的话，不太有效果\n",
    "\n",
    "\"\"\"-----------------------------------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "# 速度大于33.33m/s\n",
    "# 对于数据的异常值整体的删除\n",
    "def data_outlier_del(data):\n",
    "    data.time = pd.to_datetime(data.time)\n",
    "    data = data[::-1]\n",
    "    v = trace_car_speed(data)\n",
    "    while True in list(v>33.33):\n",
    "        v = pd.DataFrame(v, index = data.index)\n",
    "        ind_del = v[v[0]>33.33].index\n",
    "        data = data.drop(ind_del)\n",
    "        v = trace_car_speed(data)\n",
    "    data['speed_ave'] = v\n",
    "    return data\n",
    "\n",
    "\n",
    "\"\"\"-----------------------------------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def three_de(data):\n",
    "    plt.rcParams['legend.fontsize'] = 10\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    ax = fig.gca(projection='3d')  # get current axes\n",
    "\n",
    "    # Prepare arrays x, y, z\n",
    "\n",
    "    # x = pd.to_datetime(df_94000['time']).to_list()\n",
    "\n",
    "    x = [i for i in  range(len(data))]\n",
    "\n",
    "    y = data['gpsX'].to_list()\n",
    "\n",
    "    z = data['gpsY'].to_list()\n",
    "\n",
    "    ax.scatter(x, y, z, label='gps点', color='red')\n",
    "    ax.legend()  # legend content dertermined by label above\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "df_94000_6_30 = df_94000[df_94000.day == df_94000.day.iloc[0]]\n",
    "three_de(df_94000_6_30)\n",
    "\n",
    "\"\"\"-----------------------------------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.gca(projection='3d')  # get current axes\n",
    "\n",
    "# Prepare arrays x, y, z\n",
    "\n",
    "# x = pd.to_datetime(df_94000['time']).to_list()\n",
    "\n",
    "x = [i for i in  range(len(df_94000))]\n",
    "\n",
    "y = data.to_list()\n",
    "\n",
    "z = df_94000['gpsY'].to_list()\n",
    "\n",
    "ax.scatter(x, y, z, label='parametric curve', color='red', s=0.8)\n",
    "ax.legend()  # legend content dertermined by label above\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 对于连续的天数，rangelen(data)，与time的含义差不多，但是，如果数据不连续，则图形不同，时间的差异\n",
    "\"\"\"-----------------------------------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 物流数据用到的函数整合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_de(data):\n",
    "    plt.rcParams['legend.fontsize'] = 10\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    ax = fig.gca(projection='3d')  # get current axes\n",
    "\n",
    "    # Prepare arrays x, y, z\n",
    "\n",
    "    # x = pd.to_datetime(df_94000['time']).to_list()\n",
    "\n",
    "    x = [i for i in  range(len(data))]\n",
    "\n",
    "    y = data['gpsX'].to_list()\n",
    "\n",
    "    z = data['gpsY'].to_list()\n",
    "\n",
    "    ax.scatter(x, y, z, label='gps点', color='red')\n",
    "    ax.legend()  # legend content dertermined by label above\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def trace_car_speed(trace_car):\n",
    "    \"\"\"\n",
    "    :param trace_car:由take_traceofcar 返回的单个车辆轨迹数据\n",
    "    :return: 车辆每个轨迹点的速度数据\n",
    "    \"\"\"\n",
    "    # 计算每个点的速度\n",
    "    velocity_temp = np.zeros(len(trace_car))\n",
    "    # 记录从d12,d23,d(n-1,n)的距离\n",
    "    dis_temp = np.array([geodesic(trace_car.iloc[i][['gpsY', 'gpsX']], trace_car.iloc[i + 1][['gpsY', 'gpsX']]).m \\\n",
    "                         for i in range(len(trace_car) - 1)])\n",
    "    # 记录从t12,t23,t(n-1,n)的时间\n",
    "    time_temp = np.array([(trace_car.iloc[i+1]['time'] - trace_car.iloc[i]['time']).total_seconds() \\\n",
    "                          for i in range(len(trace_car) - 1)])\n",
    "\n",
    "    for i in range(len(trace_car) - 1):\n",
    "        if i == 0:\n",
    "            velocity_temp[0] = dis_temp[0] / time_temp[0]\n",
    "        elif i == len(trace_car) - 1:\n",
    "            velocity_temp[len(trace_car) - 1] = dis_temp[len(trace_car) - 2] / time_temp[len(trace_car) - 2]\n",
    "        else:\n",
    "            velocity_temp[i] = (dis_temp[i - 1] + dis_temp[i]) / (time_temp[i - 1] + time_temp[i])\n",
    "\n",
    "    return velocity_temp\n",
    "\n",
    "trace_car_speed(data_37532_1_03[::-1])\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "# 对于数据的异常值整体的删除 , 但是数据太大，大概六天跑完，放弃了，选择和推挤相关的数据进行数据的处理\n",
    "def data_outlier_del(data):\n",
    "    data.time = pd.to_datetime(data.time)\n",
    "    data = data[::-1]\n",
    "    v = trace_car_speed(data)\n",
    "    while True in list(v>33.33):\n",
    "        v = pd.DataFrame(v, index = data.index)\n",
    "        ind_del = v[v[0]>33.33].index\n",
    "        data = data.drop(ind_del)\n",
    "        v = trace_car_speed(data)\n",
    "    data['speed_ave'] = v\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"---------------------------------------------------------------------------\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## methods_of_logistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "from collections import defaultdict,OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import dateutil\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# %matplotlib inline\n",
    "\n",
    "# 这个是mac的画图中文乱码，window的可能不太一样\n",
    "# 画图中文错误\n",
    "# 用来正常显示中文标签\n",
    "# window的画图中文乱码\n",
    "# plt.rcParams['font.sans-serif'] = ['SimHei'] # 指定默认字体\n",
    "# plt.rcParams['axes.unicode_minus'] = False # 解决保存图像是负号'-'显示为方块的问题\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode Ms']\n",
    "# 用来正常显示负号\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "# 可视化矩阵\n",
    "\n",
    "\"\"\"----------------------------------------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "\n",
    "def take_traceofcar(logistics_data,ID_input,time_pd):\n",
    "    \"\"\"\n",
    "    :param ID_input: 指定车辆的ID\n",
    "    :return: 返回一个车辆位置数据的dataframe\n",
    "    \"\"\"\n",
    "    # 设置列名，分块，以及gbk编码\n",
    "    temp = [tr.loc[tr.ID == ID_input] for tr in logistics_data]  # 输入需要修改的车辆\n",
    "    if temp:\n",
    "        trace_car = pd.concat(temp)\n",
    "        trace_car[\"time\"] = pd.to_datetime(trace_car.time, format=\"%Y-%m-%dT%H:%M:%S\"). \\\n",
    "            apply(lambda x: x.replace(tzinfo=None))  # 转换为时间格式\n",
    "        trace_car = trace_car[trace_car[\"time\"]<time_pd]\n",
    "    else:\n",
    "        trace_car = pd.DataFrame()\n",
    "    \"\"\"\n",
    "    for i in trace_car.index.values:\n",
    "    trace_car['detail'][i] = re.sub(u\"\\\\[.*?\\\\]\", \"\", trace_car['detail'][i])\n",
    "    \"\"\"\n",
    "    '''\n",
    "    trace_car['detail'][i] = trace_car['detail'][i].\\\n",
    "        replace(trace_car['province'][i] + trace_car['city'][i] + trace_car['strict'][i],\"\")\n",
    "    #去掉细节地理位置中的省市区数据\n",
    "    '''\n",
    "    return trace_car\n",
    "\n",
    "\n",
    "\"\"\"----------------------------------------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "\n",
    "def car_num(trace_car):\n",
    "    # 统计每辆车的数据的最大数据值，最小，mean，以及跑的天数,车的数据大于100进行网格处理\n",
    "    \"\"\"\n",
    "    return:\n",
    "    num:放每一个数据的最大数据值，最小，mean，以及跑的天数\n",
    "    nlar_100:记录gps数据量大于等于100的数据\n",
    "    nless:记录gps数据量小于100的数据\n",
    "    \"\"\"\n",
    "    num = []\n",
    "    n1 = []\n",
    "    for j in trace_car['time'].dt.date.unique():\n",
    "        c = len(trace_car[trace_car['time'].dt.date == j])\n",
    "        n1.append([str(j), c])\n",
    "    n1 = pd.DataFrame(n1)\n",
    "    n1.set_index([0], inplace=True)\n",
    "    n1.columns = ['number']\n",
    "    #print(n1)\n",
    "\n",
    "    # 放每一个数据的最大数据值，最小，mean，以及跑的天数\n",
    "    le = len(trace_car)\n",
    "    max_ = n1['number'].max()\n",
    "    min_ = n1['number'].min()\n",
    "    mean_ = n1['number'].mean()\n",
    "    d1 = len(trace_car['time'].dt.date.unique())\n",
    "    num.append([trace_car.iloc[0][\"ID\"], le, max_, min_, mean_, d1])\n",
    "    num = pd.DataFrame(num)\n",
    "    num.set_index([0], inplace=True)\n",
    "    num.columns = ['num_total', 'num_max', 'num_min', 'num_mean', 'day_total']\n",
    "    return num, n1\n",
    "\n",
    "\n",
    "\"\"\"----------------------------------------------------------------------------------------------------------------\"\"\"\n",
    "\"\"\"\n",
    "# 对数据的预处理，\n",
    "# 网格化的处理\n",
    "1.去除 ID, 时间, 经纬度为空值的数据\n",
    "2.去重， 其实误伤大雅，可以不用管；对于同一辆车可以按照时间是否重复去重，\n",
    "3.异常值的检测：轨迹数据异常点检测\n",
    "纬度 0.001 度在地球表面任意地方对应的地\n",
    "球表面距离都是大约 100 米稍多。经度 0.001 度在赤道上对应的地球表面距离约\n",
    "为 100 cos b 米。所以图 5-4 中一个网格的面积大小为 100*87m2 其中网格内 GPS\n",
    "个数阈值设为Cthre 设为 15，距离阈值 Dthre 设为 200 米\n",
    "地球上某点的经度为A,纬度为B， 则这点的空间坐标是 x=cos(B)*cos(A) y=cos(B)*sin(A)\n",
    "x = 100 ycos(a) = cosb cosa, sina=100sina\n",
    "y = 100 xsina = cosbsina cosb = 100cosb, \n",
    "\n",
    "C_max: 每个网格中的个数\n",
    "dis_max: 每个簇之间的最大距离\n",
    "size:每个网格的大小\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# 1. 保留数据中大于10min的停止点，其余的删除\n",
    "# 2. 每一个vs_i的经纬度,用均值代替。\n",
    "# 3. 每一个数据是否为起止点，用vs_i_dis>100km, vs_i_time>7500s.\n",
    "\n",
    "def precessing(data, size):\n",
    "    data = data.dropna(subset=['time', 'gpsX', 'gpsY', 'detail'])  # 删除['time', 'gpsX', 'gpsY', 'detail']所在的行\n",
    "    # 异常值的处理， 网格的划分\n",
    "    X_grid = int((np.max(data['gpsX']) - np.min(data['gpsX'])) // size) + 1\n",
    "    Y_grid = int((np.max(data['gpsY']) - np.min(data['gpsY'])) // size) + 1\n",
    "    step_X = np.array(range(X_grid)) * size + np.min(data['gpsX']) + size * 0.5\n",
    "    step_Y = np.array(range(Y_grid)) * size + np.min(data['gpsY']) + size * 0.5\n",
    "\n",
    "    # 用列表表示，每一个列表中放的是一个pandas数据\n",
    "    R = defaultdict(list)\n",
    "    R1 = []  # 统计每一个非空的网格中的网格的中点位置，以及满足条件的数量\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        k = []\n",
    "        h = []\n",
    "        # k = np.where(np.abs(data.iloc[-1]['gpsX'] - step_X) < 5e-4)[0][0]\n",
    "        # h = np.where(np.abs(data.iloc[-1]['gpsY'] - step_Y) < 5e-4)[0][0]\n",
    "        k = (np.abs(data.iloc[i]['gpsX'] - step_X)).argmin()\n",
    "        h = (np.abs(data.iloc[i]['gpsY'] - step_Y)).argmin()\n",
    "        # 若经纬度刚好在网格格上， 则去第前一个网格\n",
    "        R[k, h].append(data.iloc[i])\n",
    "\n",
    "    for i in R.keys():\n",
    "        x_ = step_X[i[0]]\n",
    "        y_ = step_Y[i[1]]\n",
    "        lis_ = pd.DataFrame(R[i])  # 转换为pandas类型\n",
    "        count = len(lis_)  # 统计 每一个网格中的数量\n",
    "        R[i] = [[x_, y_], lis_, count]\n",
    "\n",
    "    return R\n",
    "\n",
    "\n",
    "\"\"\"----------------------------------------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "\n",
    "# 1. 基于网格删除，点的个数很小的点\n",
    "def del_less_Cmax(data, C_max=0):\n",
    "    num_ = np.array([data[i][2] for i in data.keys()])  # 统计个数\n",
    "    # print(num_)\n",
    "    if len(data) < 100:\n",
    "        C_ = 0\n",
    "    else:\n",
    "        C_ = C_max\n",
    "    data1 = defaultdict(list)  # 保留的数据\n",
    "    data2 = []  # 删除的数据的索引\n",
    "    for i in data.keys():\n",
    "        if data[i][2] < C_:\n",
    "            print(\"以下数据不满足最小的网格数据要求要删除\\n\", i, data[i][0], data[i][2])\n",
    "            data2.extend(data[i][1].index.values)\n",
    "            data[i] = []\n",
    "    # 保留不空的数据\n",
    "    for i in data.keys():\n",
    "        if data[i] != []:\n",
    "            data1[i] = data[i]\n",
    "\n",
    "    return data1, data2\n",
    "\n",
    "\n",
    "\"\"\"----------------------------------------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "\n",
    "# 2. 基于密度删除异常点\n",
    "def stats_point_del(data):\n",
    "    \"\"\"\n",
    "    统计点，然后删除小密度小于data的点\n",
    "    \"\"\"\n",
    "    mean_set = defaultdict(list)  # 定义一个新的字典，存放均值\n",
    "    point = defaultdict(list)  # 存放总的类\n",
    "    for i in data.keys():\n",
    "        if i == (0, 0):\n",
    "            pass\n",
    "        else:\n",
    "            i1 = list(data[i][1][['gpsY', 'gpsX']].mean())  # 每一个网格的平均值,\n",
    "            #             print(i1)\n",
    "            i2 = data[i][2]  # 点的个数\n",
    "            mean_set[i] = [i1, i2]\n",
    "    #             print(i2)\n",
    "\n",
    "    for i in mean_set.keys():\n",
    "        i_num = 0\n",
    "        for j in mean_set.keys():\n",
    "            if geodesic(mean_set[i][0], mean_set[j][0]) < 200:\n",
    "                i_num += mean_set[j][1]\n",
    "        # 把所有i放到一个字典\n",
    "        point[i] = [mean_set[i][0], i_num]\n",
    "    poi = []  # 记录删除的数据的索引\n",
    "    # 每一个点为中心200m的范围内，点个数小于一个常数则，认为是异常点，设置小于一个常数\n",
    "    for i in point.keys():\n",
    "        if point[i][1] < 0.01 * len(data):  # 删除密度小于len(data)*0.01的记录视为异常点\n",
    "            print(\"{}的密度低于{},应该删除:\".format(point[i][1], len(point) * 0.01))\n",
    "            poi.extend(data[i][1].index.values)\n",
    "            data[i] = []\n",
    "\n",
    "    # 对于空的字典进行处理：\n",
    "    dat = defaultdict(list)\n",
    "    for i in data.keys():\n",
    "        if data[i] != []:\n",
    "            dat[i] = data[i]\n",
    "\n",
    "    return poi, data\n",
    "\n",
    "\n",
    "\"\"\"----------------------------------------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "\n",
    "def trace_car_speed(trace_car):\n",
    "    \"\"\"\n",
    "    :param trace_car:由take_traceofcar 返回的单个车辆轨迹数据\n",
    "    :return: 车辆每个轨迹点的速度数据\n",
    "    \"\"\"\n",
    "    # 计算每个点的速度\n",
    "    velocity_temp = np.zeros(len(trace_car))\n",
    "    # 记录从d12,d23,d(n-1,n)的距离\n",
    "    dis_temp = np.array([geodesic(trace_car.iloc[i][['gpsY', 'gpsX']], trace_car.iloc[i + 1][['gpsY', 'gpsX']]).m \\\n",
    "                         for i in range(len(trace_car) - 1)])\n",
    "    # 记录从t12,t23,t(n-1,n)的时间\n",
    "    time_temp = np.array([(trace_car.iloc[i]['time'] - trace_car.iloc[i + 1]['time']).total_seconds() \\\n",
    "                          for i in range(len(trace_car) - 1)])\n",
    "\n",
    "    for i in range(len(trace_car) - 1):\n",
    "        if i == 0:\n",
    "            velocity_temp[0] = dis_temp[0] / time_temp[0]\n",
    "        elif i == len(trace_car) - 1:\n",
    "            velocity_temp[len(trace_car) - 1] = dis_temp[len(trace_car) - 2] / time_temp[len(trace_car) - 2]\n",
    "        else:\n",
    "            velocity_temp[i] = (dis_temp[i - 1] + dis_temp[i]) / (time_temp[i - 1] + time_temp[i])\n",
    "\n",
    "    return velocity_temp\n",
    "\n",
    "\n",
    "\"\"\"----------------------------------------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "\n",
    "def trace_split_Naive(trace_car, velocity_temp, max_dis_interval, max_time_interval):\n",
    "    \"\"\"\n",
    "    :param trace_car:车辆轨迹数据\n",
    "    :param velocity_temp: 车辆轨迹的速度数据\n",
    "    :param max_dis_interval: 相邻停车点间隔距离阈值\n",
    "    :param max_time_interval: 序列内普通停车点停留时间阈值\n",
    "    :return: 返回一个缺失值字典,字典每个key对应的value是一个由:\n",
    "    0.序列\n",
    "    1.轨迹点索引\n",
    "    2.序列内停留时间\n",
    "    3.类别(1:起止点,0:普通停车点)\n",
    "    组成的列表\n",
    "    \"\"\"\n",
    "\n",
    "    trace_car = trace_car.loc[::-1, :]  # 车辆轨迹反转(时间从早到晚排列)\n",
    "    velocity_temp = velocity_temp[::-1]  # 轨迹速度反转\n",
    "\n",
    "    trace_car[\"stop\"] = list((velocity_temp <= 1))  # 判断是否停车点\n",
    "    print(trace_car.head(10))  # 打印前10条数据\n",
    "\n",
    "    stop_data = trace_car[trace_car[\"stop\"] == True]  # 挑选出停车点组成pd.Dataframe\n",
    "    VS_set = defaultdict(int)  # 生成缺失键值字典\n",
    "    k = 0  # 停车点分割序列的序号\n",
    "\n",
    "    # 循环1,根据停车点间隔距离是否大于阈值分割停车点序列\n",
    "    # 记录停车轨迹点信息以及其索引\n",
    "    for i in range(len(stop_data.index.values)):\n",
    "        if i == 0:\n",
    "            VS_set[k] = [[stop_data.iloc[i]], [stop_data.index.values[i]]]\n",
    "        else:\n",
    "            if geodesic(stop_data.iloc[i - 1][['gpsY', 'gpsX']], stop_data.iloc[i][['gpsY', 'gpsX']]).m \\\n",
    "                    <= max_dis_interval:\n",
    "                VS_set[k][0].append(stop_data.iloc[i])\n",
    "                VS_set[k][1].append(stop_data.index.values[i])\n",
    "            else:\n",
    "                k += 1\n",
    "                VS_set[k] = [[stop_data.iloc[i]], [stop_data.index.values[i]]]\n",
    "\n",
    "    # 循环2,判断每个序列内时间是否大于给定停留时间阈值\n",
    "    # 记录车辆每个序列内停留时间以及是否是起止点\n",
    "    for key in VS_set.keys():\n",
    "        VS_set[key][0] = pd.DataFrame(VS_set[key][0], index=VS_set[key][1])  # 拼接轨迹点信息列表为Dataframe\n",
    "        VS_set[key].append((VS_set[key][0].time.max() - VS_set[key][0].time.min()).total_seconds())  # 计算序列内停留时间\n",
    "        VS_set[key].append((1 if VS_set[key][2] > max_time_interval else 0))  # 判断是起止停车点还是普通停车点并记录\n",
    "\n",
    "    return VS_set\n",
    "\n",
    "\n",
    "\"\"\"----------------------------------------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "\n",
    "def stop_center(VS_set):\n",
    "    \"\"\"\n",
    "    :param VS_set: 由trace_split_Naive返回的VS_set\n",
    "    :return: 返回一个包含GPS坐标列表的列表——[[*gpsX,*gpsY].....]\n",
    "    \"\"\"\n",
    "    Center_stop = {key: [np.mean(np.array(VS_set[key][0].gpsX.values)), \\\n",
    "                         np.mean(np.array(VS_set[key][0].gpsY.values))] \\\n",
    "                   for key in VS_set.keys()}\n",
    "    return Center_stop\n",
    "\n",
    "\n",
    "\"\"\"----------------------------------------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "\n",
    "def max_gps_show(trace_car, num, n1, tim):\n",
    "    \"\"\"\n",
    "    :param trace_car:车辆轨迹数据\n",
    "    :param num: 车辆每天的gps点个数\n",
    "    :param n1: 相邻停车点间隔距离阈值\n",
    "    :param tim: 序列内普通停车点停留时间阈值\n",
    "    :return: 展示某一辆车最多的GPS点的经纬度分布\n",
    "    \"\"\"\n",
    "    max_ = np.argmax(n1)\n",
    "    trace_car11 = trace_car[np.array(tim) == n1.index.values[max_]]  # 提取1天中gps数据量大于100的数据\n",
    "    df11 = precessing(trace_car11, size=0.01)  # 数据的网格划分\n",
    "    df21, df22 = del_less_Cmax(df11, C_max=5)  # 删除网格中数据小于一定5个gps数据的网格内数据, df1是处理后的数据， df2是不满足条件的异常点的索引\n",
    "    print(df22)\n",
    "    point11, data33 = stats_point_del(df21)  # 基于密度删除数据量很小的点， point是删除的点， data3是处理后的数据\n",
    "    df22.extend(point11)\n",
    "    data44 = trace_car11.drop(df22, axis=0)\n",
    "    plt.scatter(trace_car.loc[df22]['gpsX'], trace_car.loc[df22]['gpsY'], marker='*', color='red')  # 控制点的大小 s = 1\n",
    "    plt.scatter(data44['gpsX'], data44['gpsY'], marker='*', color='blue')\n",
    "    plt.xlabel(\"经度\")\n",
    "    plt.ylabel(\"纬度\")\n",
    "    plt.title(\"经度纬度图\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\"\"\"----------------------------------------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "\n",
    "def after_processing(trace_car, num, n1, tim, smaller=2):\n",
    "    \"\"\"\n",
    "    :param trace_car:车辆轨迹数据\n",
    "    :param num: 车辆每天的gps点个数\n",
    "    :param n1: 相邻停车点间隔距离阈值\n",
    "    :param tim: 序列内普通停车点停留时间阈值\n",
    "    :param smaller: 一天中数据小于2个的GPS数据删去\n",
    "    :return: 数据预处理后的值\n",
    "    1.每一辆车原数据，一天中数据小于2个的GPS数据删去\n",
    "    2. 网格处理，删除每个网格小于C_max的网格中数据，\n",
    "    3.对于每一个网格中心基于密度删除小于数据点0.01*数据总量的网格点数据\n",
    "    \"\"\"\n",
    "    print(\"ID为{}车，每天的数据描述为\\n：{}\".format(trace_car.iloc[0]['ID'], num))\n",
    "    print(n1)\n",
    "    nless_po = []  # 存储删除的数据索引\n",
    "    nlar_100 = n1[n1['number'] >= 100]\n",
    "    if smaller == 0:\n",
    "        pass\n",
    "    else:\n",
    "        nless = n1[n1['number'] < smaller]\n",
    "        for i in range(len(tim)):\n",
    "            if tim[i] in nless.index:\n",
    "                nless_po.append(trace_car.index.values[i])  # 找出每天数据小于smaller的点的索引\n",
    "\n",
    "    for i in nlar_100.index:\n",
    "        trace_car1 = trace_car[np.array(tim) == i]  # 提取1天中gps数据量大于100的数据\n",
    "        df = precessing(trace_car1, size=0.01)  # 数据的网格划分\n",
    "        df1, df2 = del_less_Cmax(df, C_max=5)  # 删除网格中数据小于一定5个gps数据的网格内数据, df1是处理后的数据， df2是不满足条件的异常点的索引\n",
    "        point, data3 = stats_point_del(df1)  # 基于密度删除数据量很小的点， point是删除的点， data3是处理后的数据\n",
    "        #  删除的点\n",
    "        nless_po.extend(df2)\n",
    "        nless_po.extend(point)\n",
    "    data4 = trace_car.drop(nless_po, axis=0)\n",
    "\n",
    "    return data4, nless_po\n",
    "\n",
    "\n",
    "\"\"\"----------------------------------------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "\n",
    "def vs_(data):\n",
    "    da_ = []\n",
    "    for i in range(len(data)):\n",
    "        if data[i][-1] == 1:\n",
    "            da_.append(a[i][0])  # 找出为1的数据，时间大于7500s,\n",
    "    da_detail = []\n",
    "    for i in range(len(da_)):\n",
    "        index = da_[i].index.values[0]  # 索引\n",
    "        ID = da_[i].iloc[0]['ID']\n",
    "        x0 = np.mean(da_[0]['gpsX'])\n",
    "        y0 = np.mean(da_[0]['gpsY'])\n",
    "        x = np.mean(da_[i]['gpsX'])\n",
    "        y = np.mean(da_[i]['gpsY'])\n",
    "        t_start = da_[i].iloc[0]['time']\n",
    "        time_process = (da_[i].iloc[-1]['time'] - da_[i].iloc[0]['time']).total_seconds()\n",
    "        if i == 0:\n",
    "            prevdis = 0\n",
    "        else:\n",
    "            # np.mean(data) 按列求均值, np.mean(data, axis=1):按行\n",
    "            prevdis = geodesic(np.mean(da_[i - 1][['gpsY', 'gpsX']]), np.mean(da_[i][['gpsY', 'gpsX']])).m\n",
    "        da_detail.append([index, ID, x, y, t_start, time_process, prevdis])\n",
    "    da_detail = pd.DataFrame(da_detail,\n",
    "                             columns=['index', 'ID', 'gpsX_mean', 'gpsY_mean', 't_start', 'time_process', 'prevdis'])\n",
    "    # 注意两点之间若不直接行走，则经纬度计算的距离不等于该两点间的路程。\n",
    "    # D=pd.Series(range(0,20)), D.cumsum(axis)  累计求和\n",
    "    da_detail['odm'] = da_detail['prevdis'].cumsum()\n",
    "    return da_detail\n",
    "\n",
    "\n",
    "\"\"\"----------------------------------------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "\n",
    "def split_stop_ordinary_point(vs_, v_max=100000, tao_max=7500):\n",
    "    \"\"\"\n",
    "    vs_:一条轨迹\n",
    "    v_max:相邻停车点的距离阈值\n",
    "    tao_max:停车时间阈值\n",
    "    \"\"\"\n",
    "    prevdis = 0\n",
    "    RS = []\n",
    "    CS = []  # RS:起止停车点；CS:普通停车点\n",
    "    for i in range(len(vs_)):\n",
    "        if i == 0:\n",
    "            if vs_['time_process'][0] >= tao_max:\n",
    "                RS.append(vs_.iloc[0])\n",
    "            else:\n",
    "                CS.append(vs_.iloc[0])\n",
    "        else:\n",
    "            vsi_prevdis = vs_['odm'][i] - prevdis\n",
    "            if (vsi_prevdis >= v_max) & (vs_['time_process'][i] >= tao_max):\n",
    "                prevdis = vs_['odm'][i]\n",
    "                RS.append(vs_.iloc[i])\n",
    "            else:\n",
    "                CS.append(vs_.iloc[i])\n",
    "    RS = pd.DataFrame(RS)\n",
    "    # 查看是否每条数据间的距离大于100km\n",
    "    delta = []\n",
    "    for i in range(0, len(RS['odm'])):\n",
    "        if i == 0:\n",
    "            delta.append(RS.iloc[0]['odm'])\n",
    "        else:\n",
    "            delta.append(RS.iloc[i]['odm'] - RS.iloc[i - 1]['odm'])\n",
    "    RS[\"delta_prevdis\"] = delta\n",
    "    return RS, pd.DataFrame(CS)\n",
    "\n",
    "\n",
    "\"\"\"----------------------------------------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "\n",
    "def home_identifier(VS_set):\n",
    "    \"\"\"\n",
    "    :param VS_set: 由trace_split_Naive返回的VS_set\n",
    "    :return: 返回一个列表，包含一辆车根据停车点数据挖掘出的返程城市（省+市）\n",
    "    \"\"\"\n",
    "    home_summary = defaultdict(int)\n",
    "    for value in VS_set.values():\n",
    "        if value[2] > 7:\n",
    "            home_summary[str(value[0].iloc[0].province) + str(value[0].iloc[0].city)] += 1\n",
    "    if home_summary:\n",
    "        temp = max(home_summary.values())\n",
    "        home = []\n",
    "        for key in home_summary.keys():\n",
    "            if home_summary[key] == temp:\n",
    "                home.append(key)\n",
    "    else:\n",
    "        # 如果没有停留7小时以上，说明数据量太少，不考虑返程\n",
    "        home = []\n",
    "\n",
    "    return home\n",
    "\n",
    "\n",
    "\"\"\"----------------------------------------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "\n",
    "def route_familiar(VS_set):\n",
    "    \"\"\"\n",
    "    :param VS_set: 由trace_split_Naive返回的VS_set\n",
    "    :return: 返回一个defaultdict,字典的键为城市的二元组,字典的值为经过二元组的次数\n",
    "    \"\"\"\n",
    "    spot_counter = len(VS_set)\n",
    "    spot_summary = [str(VS_set[i][0].iloc[0].province) + str(VS_set[i][0].iloc[0].city) for i in range(spot_counter)]\n",
    "    route_f = defaultdict(int)\n",
    "\n",
    "    for j in range(spot_counter - 1):\n",
    "        if spot_summary[j] != spot_summary[j + 1]:\n",
    "            route_f[frozenset([spot_summary[j], spot_summary[j + 1]])] += 1\n",
    "\n",
    "    return route_f\n",
    "\n",
    "\n",
    "\"\"\"----------------------------------------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "\n",
    "def sort_value(default_dict, reverse=True):\n",
    "    \"\"\"\n",
    "    对字典按 value 排序,默认降序,不修改原先字典\n",
    "    :param default_dict:接受一个默认字典（route_familiar返回）\n",
    "    :param reverse:是否降序\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    items = sorted(default_dict.items(), key=lambda obj: obj[1], reverse=reverse)  # 获取按value排序后的元组列表\n",
    "    ordered_dict = OrderedDict()  # 创建一个新的空字典\n",
    "    for item in items:  # 遍历 items 列表\n",
    "        ordered_dict[item[0]] = default_dict[item[0]]\n",
    "\n",
    "    return ordered_dict\n",
    "\n",
    "\n",
    "\"\"\"----------------------------------------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "\n",
    "# 首先筛选时间（之后再筛选方数、吨数等）\n",
    "def time_filter(time_pd, days, data):\n",
    "    '''\n",
    "    :param time_pd: 输入pandas时间\n",
    "    :param days: 输入提前时间\n",
    "    :param data: 输入读取的数据\n",
    "    :return: 返回一个经过时间筛选的数据\n",
    "    '''\n",
    "    temp = data[((data[\"time\"] <= time_pd) & \\\n",
    "                 (data[\"time\"] >= time_pd - dateutil.relativedelta.relativedelta(days=days)))]\n",
    "    return temp\n",
    "\n",
    "\n",
    "\"\"\"----------------------------------------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "\n",
    "def shape_filter(weight, volume, data):\n",
    "    '''\n",
    "    :param weight: 需要吨数\n",
    "    :param volume: 需要方数\n",
    "    :param data: 输入数据\n",
    "    :return: 返回一个经过重量与方数筛选的数据\n",
    "    '''\n",
    "    data_filtered = data[(data['最大吨数'] >= weight) & (data['最大方数'] >= volume)]\n",
    "    return data_filtered\n",
    "\n",
    "\n",
    "\"\"\"----------------------------------------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "\n",
    "def car_filtered(data, speed, last_time,gpsList,time_pd):\n",
    "    cars = list(set(data.ID.values))\n",
    "    c = dict()\n",
    "    car_trace_0 = data[\n",
    "        data.time < ( time_pd- dateutil.relativedelta.relativedelta(hours=last_time))]\n",
    "    for car in cars:\n",
    "        car_trace = car_trace_0[car_trace_0.ID == car]\n",
    "        car_trace = car_trace.loc[::-1, :]\n",
    "        if len(car_trace) != 0:\n",
    "            c[car] = 1 if (float(str(geodesic([car_trace.iloc[0].gpsY, car_trace.iloc[0].gpsX], \\\n",
    "                                              gpsList)) \\\n",
    "                                 .replace(\" km\", \"\")) / speed) < (last_time - 1) else 0\n",
    "    return c\n",
    "    # 车辆八小时提货时间八小时（交付时间七小时前）所在的点距离提货点的距离是否能即使到车\n",
    "\n",
    "\n",
    "\"\"\"----------------------------------------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "136px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
